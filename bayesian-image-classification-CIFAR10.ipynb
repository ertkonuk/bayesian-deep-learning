{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image classification with PyTorch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# . . tugrul konuk\n",
    "# . . this notebook implements and modifies the methods and ideas presented in the paper \n",
    "# . . \"End to end Learning for Self-Driving Cars\"\n",
    "# . . https://arxiv.org/pdf/1604.07316v1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . import libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "# . . pytorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# . . numpy\n",
    "import numpy as np\n",
    "# . . scikit-learn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# . . matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as npimg\n",
    "# . .  set this to be able to see the figure axis labels in a dark theme\n",
    "from matplotlib import style\n",
    "#style.use('dark_background')\n",
    "# . . to see the available options\n",
    "# print(plt.style.available)\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# . . import libraries by tugrulkonuk\n",
    "import utils\n",
    "#from dataset import Dataset\n",
    "from model import *\n",
    "from trainer import Trainer\n",
    "from callbacks import ReturnBestModel, EarlyStopping\n"
   ]
  },
  {
   "source": [
    "# set device and precision"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . set the device\n",
    "if torch.cuda.is_available():  \n",
    "    device = torch.device(\"cuda\")  \n",
    "else:  \n",
    "    device = torch.device(\"cpu\")      \n",
    "\n",
    "#device = torch.device(\"cpu\")      \n",
    "# . . set the default tensor to cuda: DO NOT USE THIS\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# . . set the default precision\n",
    "dtype = torch.float32\n",
    "\n",
    "# . . use cudnn backend for performance\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . arguments . .\n",
    "# . . this is only for the Jupyter notebook as there is no command line\n",
    "class Args():\n",
    "    # . . number of epochs \n",
    "    epochs = 100\n",
    "\n",
    "    # . . the learning rate \n",
    "    lr = 0.001\n",
    "\n",
    "    # . . batch_size\n",
    "    batch_size = 1024\n",
    "\n",
    "    # . . fraction of data to be used in training\n",
    "    train_size = 0.8\n",
    "\n",
    "    # . . min delta (min improvement) for early stopping\n",
    "    min_delta = 0.0005\n",
    "\n",
    "    # . . patience for early stopping\n",
    "    patience = 10\n",
    "\n",
    "    # . . number of workers for the data loader\n",
    "    num_workers = 8\n",
    "\n",
    "    # . . use pinn memory for faster CPU-GPU transler\n",
    "    pin_memory = False\n",
    "\n",
    "    # . . print interval\n",
    "    jprint = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . instantiate the command-line parameters object\n",
    "args = Args()\n",
    "\n",
    "# . . get command-line parameters\n",
    "num_epochs    = args.epochs\n",
    "batch_size    = args.batch_size\n",
    "learning_rate = args.lr\n",
    "train_size    = args.train_size\n",
    "min_delta     = args.min_delta\n",
    "patience      = args.patience \n",
    "num_workers   = args.num_workers\n",
    "pin_memory    = args.pin_memory\n",
    "jprint        = args.jprint"
   ]
  },
  {
   "source": [
    "## import the data\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . transformer for data augmentation\n",
    "transformer_train = torchvision.transforms.Compose([\n",
    "  # torchvision.transforms.ColorJitter(\n",
    "  #     brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "  # torchvision.transforms.RandomRotation(degrees=15),\n",
    "  torchvision.transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "  # torchvision.transforms.RandomPerspective(),\n",
    "  transforms.ToTensor(),                                            \n",
    "])\n",
    "\n",
    "# . . the train set\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='.',\n",
    "    train=True,\n",
    "    transform=transformer_train,\n",
    "    download=True)\n",
    "\n",
    "# . . the validation set: no augmentation!\n",
    "valid_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='.',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . the number of classes in the data\n",
    "num_classes = len(set(train_dataset.targets))\n",
    "print('number of classes: ',num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . the training loader: shuffle\n",
    "trainloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                         num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "# . . the test loader: no shuffle\n",
    "validloader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "# . . instantiate the model\n",
    "model = BayesianCNNClassifierCIFAR(in_channels, num_classes, lrt=False)\n",
    "\n",
    "# . . send model to device (GPU)\n",
    "model.to(device)"
   ]
  },
  {
   "source": [
    "# . . show a summary of the model\n",
    "summary(model, (3, 32, 32))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . . create the trainer\n",
    "trainer = Trainer(model, device)\n",
    "\n",
    "# . . compile the trainer\n",
    "# . . define the loss\n",
    "class elbo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(elbo, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, kl, beta, batch_size):\n",
    "        assert not target.requires_grad\n",
    "        return F.nll_loss(input, target, reduction='mean') * batch_size + beta * kl\n",
    "\n",
    "criterion = elbo().to(device)\n",
    "\n",
    "# . . define the optimizer\n",
    "optimparams = {'lr':learning_rate\n",
    "              }\n",
    "\n",
    "# . . define the callbacks\n",
    "cb=[ReturnBestModel(), EarlyStopping(min_delta=min_delta, patience=patience)]\n",
    "\n",
    "trainer.compile(optimizer='adam', criterion=criterion, callbacks=cb, jprint=jprint, **optimparams)\n",
    "\n",
    "# . . the learning-rate scheduler\n",
    "schedulerparams = {'factor':0.5,\n",
    "                   'patience':50,\n",
    "                   'threshold':1e-5,\n",
    "                   'cooldown':5,\n",
    "                   'min_lr':1e-5,                \n",
    "                   'verbose':True               \n",
    "                  }\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(trainer.optimizer, **schedulerparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# . . train the network\n",
    "train_loss, valid_loss = trainer.fit(trainloader, validloader, scheduler=None, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(valid_loss)\n",
    "plt.legend(['train_loss', 'valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch_size = 32\n",
    "\n",
    "# . . training dataset without augmentation\n",
    "train_dataset_noaug = torchvision.datasets.CIFAR10(\n",
    "                      root='.',\n",
    "                      train=True,\n",
    "                      transform=transforms.ToTensor(),\n",
    "                      download=True)\n",
    "\n",
    "# . . data loader for the training dataset without transforms\n",
    "trainloader_noaug = torch.utils.data.DataLoader(\n",
    "                     dataset=train_dataset_noaug, \n",
    "                     batch_size=eval_batch_size, \n",
    "                     shuffle=False,\n",
    "                     num_workers=num_workers,\n",
    "                     pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy, test_accuracy = trainer.evaluate(trainloader_noaug, validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#. . calculate and plot the confusion matrix\n",
    "x_test = valid_dataset.data\n",
    "y_test = np.array(valid_dataset.targets)\n",
    "p_test = np.array([])\n",
    "\n",
    "num_ensemble = 1\n",
    "for inputs, targets in validloader:\n",
    "    # . . move to device\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "    # . . prepare the outputs for multiple ensembles\n",
    "    outputs = torch.zeros(inputs.shape[0], trainer.model.num_classes, num_ensemble).to(device)\n",
    "                \n",
    "    # . . feed-forward network: multiple ensembles\n",
    "    kl_div = 0.0                \n",
    "    for ens in range(num_ensemble):\n",
    "        outputs_, kl_div_ = trainer.model(inputs)\n",
    "        # . . accumulate the kl div loss\n",
    "        kl_div += kl_div_\n",
    "        # . . keep the outputs\n",
    "        outputs[:,:,ens] = F.log_softmax(outputs_, dim=1).data\n",
    "\n",
    "    # . . normalise the kl div loss over ensembles\n",
    "    kl_div /= num_ensemble\n",
    "\n",
    "    # . . make sure the outputs are positive\n",
    "    log_outputs = utils.logmeanexp(outputs, dim=2)\n",
    "    #log_outputs = torch.mean(outputs, dim=2)\n",
    "\n",
    "    # . . network predictions\n",
    "    _, predictions = torch.max(log_outputs, 1)\n",
    "\n",
    "    # . . update the p-test\n",
    "    p_test = np.concatenate((p_test, predictions.cpu().numpy()))\n",
    "\n",
    "# . . the confusion matrix\n",
    "cm = confusion_matrix(y_test, p_test)\n",
    "\n",
    "# . . plot the confusion matrix \n",
    "utils.plot_confusion_matrix(cm, list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model.state_dict(), 'models/final_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "36b8c84fc314970b549a5ccdac76fb7190d06254b4f13830a348ec2d14d43812"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}